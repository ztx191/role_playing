# -*- coding: utf-8 -*-
# LLM Config
LLM_NAME_OR_PATH = D:\model\Qwen2.5-0.5B-Instruct
# LLM_NAME_OR_PATH = D:\model\Qwen1.5-1.8B-chat
LLM_QUANTIZED = False
LLM_TEMPERATURE = 0.1
LLM_MAX_NEW_TOKEN = 1024
LLM_DEVICE = cuda
LLM_CACHE_DIR =
LLM_LORA_PATH =
LLM_BASE_API =
LLM_API_KEY =


# Role Setting
ROLE_SYSTEM_SETTING = model_template/prompt/system_setting.txt
ROLE_CHARACTER_CARDS_PATH = model_template/character_cards
ROLE_HISTORY_PROMPT = model_template/prompt/history_prompt.txt
ROLE_OPENING_REMARKS = model_template/prompt/opening_remarks.txt
ROLE_RAG_PROMPT = model_template/prompt/rag_prompt.txt
ROLE_CHAT_HISTORY_PATH = chat_history
# size是不为零的偶数
ROLE_CHAT_HISTORY_SIZE = 8

# RAG Setting
RAG_EMBEDDING_MODEL =
RAG_RANKER_MODEL =
RAG_VECTOR_DB =
RAG_TOK_K = 3

